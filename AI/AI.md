# å¹¶è¡Œ
## reduceçš„å«ä¹‰
![](20250702124040.png)
## batch ä¸ å¹¶è¡Œè®­ç»ƒçš„å…³ç³»
![](20250702124200.png)
## BN ä¸ å¹¶è¡Œè®­ç»ƒçš„å…³ç³»
![](20250702124737.png)
## å¦‚ä½•å¯åŠ¨å¤šä¸ªè¿›ç¨‹
### æ–¹å¼ä¸€
![](20250702124805.png)

### æ–¹å¼äºŒ
![](20250702124830.png)
## DistInfiniteBatchSamplerä¸­çš„disté’ˆå¯¹çš„æ˜¯torchrunè¿˜æ˜¯numworker
![](20250708152652.png)
## ä½¿ç”¨launchå¯åŠ¨torchrun åªèƒ½è°ƒè¯•å­è¿›ç¨‹
![](20250802095825.png)
![](20250802095907.png)


# AI


## TCPstore
![](20250702124854.png)
## torch.empty(1).cuda().device
![](20250702125006.png)
![](20250702125016.png)
## cudnnåº“
![](20250703123624.png)
## å¢å¤§å­¦ä¹ ç‡kå€æ˜¯å¦ç­‰ä»·äºlossæ”¾å¤§kå€
![](20250703144316.png)
## weight decay
![](20250725131034.png)
## å±‚çº§å­¦ä¹ ç‡
![](20250725131229.png)
![](20250725131239.png)
## æ¢¯åº¦ç´¯ç§¯ accum_steps
![](20250726111856.png)
## æ¢¯åº¦è£å‰ª grad_clip
![](20250726111927.png)
![](20250806153228.png)
## RMSNorm
![](20250729202757.png)
![](20250729202806.png)
## extra_repr()
 ![](20250729203515.png)
## åå‘ä¼ æ’­
![](20250730111159.png)
![](20250730111210.png)
## KV_cache
https://zhuanlan.zhihu.com/p/662498827
![](20250824113900.png)
![](20250824113911.png)
## multi-head
![](20250730204423.png)
## flex_attn
https://pytorch.org/blog/flexattention/
## score
![](20250731175047.png)

# DistributedDataParallel
## device_ids=Noneå‚æ•°è¡Œä¸ºåˆ†æ
![](20250709125101.png)
## å•GPUæ¨¡å‹ï¼Œè·¨å¤šä¸ªGPUåˆ†å¸ƒæ¨¡å‹
![](20250709125640.png)
## broadcast_buffers
![](20250709151204.png)
![](20250709151115.png)
![](20250709151128.png)
![](20250709151138.png)
## init_sync
![](20250709153156.png)
## process_group 
![](20250709160241.png)
![](20250709160249.png)


# æ¨¡å‹
## silu,sequential
![](20250708205243.png)
## unbind
![](20250708205257.png)
## FastRMSNorm vs nn.LayerNorm
![](20250708210938.png)
## norm_layer(C, elementwise_affine=False)
![](20250708211124.png)
![](20250708211148.png)
## self.head_nm.ada_lin[-1].weight.data.mul_(aln_init)
## self.head_nm.ada_lin[-1].bias.data.zero_()
![](20250708212127.png)
![](20250708212153.png)
## nn.linear, bias
![](20250708212653.png)
![](20250708212722.png)
## ä¸¤ç§ä¸åŒçš„æ¨¡å‹å‚æ•°åˆå§‹åŒ–æ–¹æ³•
![](20250708200245.png)
## é»˜è®¤åˆå§‹åŒ–æ–¹æ³•æ˜¯kaiming_uniform_ 
![](20250708234544.png)
## nn.parameters()ä¸nn.modules()çš„åŒºåˆ«
éƒ½æ˜¯é€’å½’çš„
![](20250709112307.png)
![](20250709112315.png)
## count_p = lambda m: f'{sum(p.numel() for p in m.parameters()) / 1e6:.2f}'
è¿™æ˜¯ä¸€ä¸ªå‡½æ•°,æ¥å—å‚æ•°m
![](20250709121849.png)
## TorchScript / ONNX
![](20250731110247.png)
![](20250731110301.png)
![](20250731110312.png)
## DropPath
 ![](20250801085105.png)
## CrossEntropyLoss
å…¶ä¸­yiè¡¨ç¤ºæ¦‚ç‡ï¼Œæœ€ç»ˆlossè¶Šä½è¶Šå¥½
![](20250817154709.png)

# PythonçŸ¥è¯†

## pyiæ–‡ä»¶çš„ä½œç”¨
![](20250702131230.png)
## python vscode è°ƒè¯•é»˜è®¤ä¸è¿›å…¥ç¬¬ä¸‰æ–¹ä»£ç 
![](20250702160737.png)
## å‡½æ•°å‚æ•°é»˜è®¤å€¼
![](20250702161559.png)
## Optionalçš„ä¼˜ç‚¹
![](20250702161708.png)
## stdoutä¸stderr
![](20250703121552.png)
## torchæ£€æµ‹åå‘æ¢¯åº¦é”™è¯¯
![](20250703122443.png)
## or
![](20250703144437.png)
## æµ®ç‚¹æ•°è½¬å­—ç¬¦ä¸²
![](20250703150430.png)
## re.compile(r'[^\w\-+,.]')çš„ç”¨æ³•
![](20250703150801.png)
![](20250703150814.png)
## sorted(glob.glob(pattern, recursive=recursive), key=os.path.getmtime, reverse=True)
![](20250703151536.png)
## tb_lg: misc.TensorboardLogger
![](20250703153337.png)
## get_attr
![](20250703160422.png)
## diskloggerçš„ä½œç”¨
![](20250703181645.png)
## __call__
![](20250703183316.png)
## modeç±»å‹
mode = {
    1: 'reduce-overhead',
    2: 'max-autotune',
    3: 'default',
}[fast]
çš„ç»“æœç±»å‹æ˜¯å­—ç¬¦ä¸²ï¼ˆstrï¼‰ã€‚
## partial
![](20250708210915.png)
## Union
![](20250708233027.png)
## for block_idx, sab in enumerate(self.unregistered_blocks):
block_idxæ˜¯ä»0å¼€å§‹
## sab.sa.proj.weight.data.mul_(scale)
![](20250708233836.png)
## @staticmethod
![](20250730104021.png)
![](20250730104032.png)
## @classmethod
![](20250730104101.png)
## [::-1]
![](20250804173924.png)
## lambda lamuda
![](20250804180948.png)

# torchè®¡ç®—

## torchä¹˜æ³•ç²¾åº¦
![](20250703122929.png)
## æ¢¯åº¦ç§¯ç´¯
![](20250703125808.png)
![](20250703125817.png)
## state_dict()
![](20250708163542.png)
## æ¨¡å‹checkpointä¸¤ç§å½¢å¼
![](20250708163724.png)
![](20250708163738.png)
## è®¡ç®—å›¾checkpointåŸç†
![](20250703145452.png)
## ckptä¸­çš„epå’Œit
![](20250703152459.png)
## torch.compile(åŠ é€Ÿæ¨ç†)
![](20250708194445.png)
![](20250708194520.png)
## torch.cuda.synchronize()
![](20250709153846.png)
## named_parameters
![](20250709155627.png)
## ndim
![](20250709155803.png)
## tensor.item()
æ³¨ï¼šåªæœ‰shapeä¸º0çš„æ—¶å€™æ‰å¯ä»¥ç”¨item()
![](20250725164251.png)
## torch.cuda.amp.autocast()
![](20250726103838.png)
## torch.cuda.amp.GradScaler()
![](20250726104053.png)
![](20250726112232.png)
##  for t in optimizer_state['found_inf_per_device'].values(): dist.allreduce(t)
![](20250726165900.png)
![](20250726165924.png)
![](20250726165958.png)
## allreduce
![](20250726170205.png)
![](20250726170210.png)
## f_hat = gt_ms_idx_Bl[0].new_zeros(B, C, H, W, dtype=torch.float32)
![](20250728164128.png)
## expand
![](20250729094313.png)
## torch.full
![](20250729095614.png)
## contiguous()
![](20250729100722.png)
## [:, 0]
![](20250729100831.png)
## register_buffer()
![](20250729101109.png)
## x_BLC.new_ones(8, 8)
![](20250729101323.png)
## nn.embedding
![](20250729105051.png)
## pad
![](20250729160731.png)
## dropout
![](20250731092945.png)
![](20250731093007.png)
## optimizer.load_state_dict()
![](20250731105827.png)
## unbind
![](20250731153151.png)
## clamp
å…·ä½“æ¥è¯´ï¼Œclamp(min=1e-12) ä¼šå°† cdf_plus ä¸­æ‰€æœ‰å°äº 1e-12ï¼ˆå³ 0.000000000001ï¼‰çš„å€¼éƒ½æ›¿æ¢ä¸º 1e-12ï¼Œè€Œå¤§äºæˆ–ç­‰äºè¿™ä¸ªå€¼çš„å…ƒç´ åˆ™ä¿æŒä¸å˜ã€‚
## mean
![](20250804175501.png)
## nn.CrossEntropyLoss(label_smoothing=label_smooth, reduction='none')  è¿™é‡Œçš„label_smoothingæ˜¯å•¥æ„æ€
![](20250804185544.png)
![](20250804185614.png)
## bincount 
![](20250806154413.png)
## unsqueeze(dim)
![](20250824110017.png)


# dataloder
## samplerå’Œbatch_samplerçš„åŒºåˆ«
![](20250707190717.png)
![](20250707190726.png)
## samplerä¸¾ä¾‹
![](20250708121226.png)
## samplerä¸­çš„__len__æ˜¯ä»€ä¹ˆæ„æ€
æˆ‘ä»¬å¯ä»¥å¾—å‡ºç»“è®º,len(sampler)å°±æ˜¯ä¸€ä¸ªepochä¸­çš„iterationä¸ªæ•°
![](20250708130253.png)
## collate_fn
![](20250707192318.png)
![](20250707193622.png)
## default_collate(),ä¹Ÿå°±æ˜¯é»˜è®¤çš„collate_fn
![](20250707192354.png)
![](20250707192404.png)
![](20250707192412.png)
## dataloder ä¼šè‡ªåŠ¨æ‰§è¡Œ pin_memoryå—
![](20250707195137.png)
## timeoutå‚æ•°ä¸€æ—¦è¶…è¿‡æ—¶é—´å°±æŠ¥é”™é€€å‡º
![](20250707195336.png)
## generatorå‚æ•°
![](20250707204441.png)
![](20250707204452.png)
## torch.generator()
![](20250708121923.png)
## æ¯ä¸ªworkerï¼ˆdataloderä¸­çš„workerï¼‰æ˜¯å¦å¤„ç†ä¸€å°éƒ¨åˆ†batchï¼Œç„¶åå†æ‹¼èµ·æ¥
![](20250707212940.png)
## prefetch_factor
prefetch_factor (int, optional, keyword-only arg): Number of batches loaded
    in advance by each worker. ``2`` means there will be a total of
    2 * num_workers batches prefetched across all workers. (default value depends
    on the set value for num_workers. If value of num_workers=0 default is ``None``.
    Otherwise, if value of ``num_workers > 0`` default is ``2``).
![](20250707213100.png)
## persistent_workers 
(bool, optional): If ``True``, the data loader will not shut down
            the worker processes after a dataset has been consumed once. This allows to
            maintain the workers `Dataset` instances alive. (default: ``False``)
## pin_memory_device
![](20250707213646.png)
## in_order
![](20250707213833.png)

# pythonè®¡ç®—

## tuple
![](20250703124537.png)
å®é™…ï¼š
![](20250703124742.png)
## __iter__()
![](20250708121409.png)
## listä¸__iter__()
![](20250708121438.png)
## indices[:tails]
![](20250708132538.png)
## è¿­ä»£å™¨çš„ä½¿ç”¨,ä¸¤ç§æ–¹æ³•:forä¸iter
![](20250708161053.png)
## opt_kw = dict(lr=args.tlr, weight_decay=0)
![](20250725155146.png)
## defaultdict(SmoothedValue)
![](20250725164808.png)
## fmt.format
![](20250725165543.png)
## datetime.timedelta(seconds=...)
![](20250725174831.png)
## etaæ˜¯ä»€ä¹ˆæ„æ€
![](20250725174911.png)
## with
![](20250728184232.png)
![](20250728184432.png)
## /
![](20250801161902.png)
## def continuous_gaussian_log_likelihood(x, *, means, log_scales):
åœ¨ Python å‡½æ•°å®šä¹‰ä¸­ï¼Œå‚æ•°åˆ—è¡¨ä¸­çš„ * æœ‰ä¸€ä¸ªç‰¹æ®Šçš„ä½œç”¨ï¼Œå®ƒè¡¨ç¤º * ä¹‹åçš„æ‰€æœ‰å‚æ•°éƒ½å¿…é¡»ä»¥ å…³é”®å­—å‚æ•°ï¼ˆkeyword argumentsï¼‰çš„å½¢å¼ä¼ é€’ï¼Œè€Œä¸èƒ½ä»¥ä½ç½®å‚æ•°ï¼ˆpositional argumentsï¼‰çš„å½¢å¼ä¼ é€’ã€‚
## kw = dict(z_voc_usage=cluster_usage)
kw = {"z_voc_usage": cluster_usage}
## round(x)
å››èˆäº”å…¥
## str(datetime.timedelta(seconds=...))
![](20250817154110.png)
## time.strftime("%Y-%m-%d %H:%M", time.localtime(time.time() + remain_secs))
![](20250817154242.png)
## _reg_valid_name.sub
![](20250817175022.png)


# é¢å‘å¯¹è±¡

## å¤šæ€
![](20250708131917.png)
## å­ç±»è°ƒç”¨äº†çˆ¶ç±»çš„æ–¹æ³•ï¼Œè€Œçˆ¶ç±»çš„æ–¹æ³•ä¸­ç”¨åˆ°äº† self.xxx è¿™æ ·çš„æˆå‘˜å˜é‡
![](20250708150042.png)
## çˆ¶ç±»åˆå§‹åŒ–
![](20250708150118.png)
## x = torch.tensor([[1, 2],[3, 4]])å½¢çŠ¶
torch.Size([2, 2])
## repeat_interleave
![](20250725165659.png)
![](20250725165722.png)
## @property
![](20250725165509.png)
## shutil.copy(local_out_ckpt, local_out_ckpt_best)
![](20250817170322.png)



# np

## np.linspace
np.linspace(2.0, 3.0, num=5)
array([2.  , 2.25, 2.5 , 2.75, 3.  ])
np.linspace(2.0, 3.0, num=5, endpoint=False)
array([2. ,  2.2,  2.4,  2.6,  2.8])
np.linspace(2.0, 3.0, num=5, retstep=True)
(array([2.  ,  2.25,  2.5 ,  2.75,  3.  ]), 0.25)
## np.prod
![](20250801164635.png)
## np.cumprod
![](20250803163148.png)

# var

## æ–‡ä»¶

printåœ¨misc.pyæ–‡ä»¶é‡Œ

if args.pg:  # åªæœ‰è®¾ç½®äº† progressive trainingï¼ˆpg > 0.0ï¼‰æ‰ä¼šè¿›å…¥

g_it å…¨å±€æ­¥æ•°

stepping å½“å‰è½®æ˜¯å¦æ‰§è¡Œåå‘æ›´æ–°ï¼Œè¿™ä¸ªå‚æ•°ä¸æ¢¯åº¦ç´¯ç§¯ accum_stepsæœ‰å…³

## å˜é‡

## f, f_hat
æ³¨æ„ f_hatä¸æ˜¯indexï¼Œè€Œæ˜¯embedding
![](20250728104753.png)
## f_hat_or_idx_Bl
![](20250728113035.png)
## gt_idx_Bl_super åŒæ—¶ä¹Ÿæ˜¯ f_hat_or_idx_Bl
![](20250728113354.png)
## f_hat_super
shape = torch.Size([4, 32, 16, 16])
## gt_BL_super
torch.Size([4, 680])
## quant_resiæ¨¡å—
![](20250728115151.png)
## idxBl_to_var_inputå‡½æ•°
ç”¨æ¥è·å–varçš„input
![](20250728115731.png)
## x_BLCv_wo_first_l_super
shape = torch.Size([4, 679, 32])
## scale_schedule
![](20250728185948.png)
## torch.tensor([lowLen] * B, dtype=torch.int32)
![](20250729113200.png)
## label_B
torch.Size([4]) è¡¨ç¤ºæ ‡ç­¾
## need_to_pad
![](20250729160934.png)
## shared_ada_lin
![](20250731112322.png)
## act, ada_lin, gss
act: activation
ada_lin: Adaptive LayerNorm Parameter Linear Mapper
ada_gss: gamma, scale, shift
## shared_aln
ç”¨äºæ§åˆ¶æ˜¯å¦ å…±äº«ä¸€ç»„ LayerNorm å‚æ•°ï¼ˆÎ³/Î²ï¼‰ï¼Œè€Œä¸æ˜¯å¯¹æ¯ä¸ªæ ·æœ¬é€šè¿‡æ¡ä»¶å‘é‡å•ç‹¬ç”Ÿæˆã€‚
![](20250731152147.png)
## approx_standard_normal_cdf
è¿™æ˜¯ä¸€ä¸ªç”¨äºå¿«é€Ÿè¿‘ä¼¼è®¡ç®—æ ‡å‡†æ­£æ€åˆ†å¸ƒçš„ ç´¯ç§¯åˆ†å¸ƒå‡½æ•°ï¼ˆCumulative Distribution Function, CDFï¼‰çš„å‡½æ•°ã€‚
## def continuous_gaussian_log_likelihood(x, *, means, log_scales):
![](20250802152038.png)
## def normal_kl(mean1, logvar1, mean2, logvar2):
![](20250802152209.png)
![](20250802152343.png)
## metric
| åç§° | ä½œç”¨ |
| --- |  --- | 
| `tlr` total learning rate | æœ€å¤§å­¦ä¹ ç‡ | 
| `tnm` Total Norm | = grad_normï¼Œ æ‰€æœ‰æ¢¯åº¦çš„L2èŒƒå¼ | 
| `Lm`  | logits_BLVå’Œgt_BL_superçš„äº¤å‰ç†µï¼Œlogits_BLV.shape = ï¼ˆBï¼ŒLï¼ŒVï¼‰ | 
| `Lt` | tailçš„äº¤å‰ç†µ | 
| `Accm` | æ‰€æœ‰tokençš„æ­£ç¡®ç‡ï¼Œ acc_mean = (pred_BL == gt_BL_super).float().mean().item() * 100 # int | 
| `Acct` | tailï¼ˆä¹Ÿå°±æ˜¯æœ€åä¸€å±‚ 16 * 16ï¼‰tokençš„æ­£ç¡®ç‡ | 
| `tnm` | = grad_normï¼Œ æ‰€æœ‰æ¢¯åº¦çš„L2èŒƒå¼ | 
| `tnm` | = grad_normï¼Œ æ‰€æœ‰æ¢¯åº¦çš„L2èŒƒå¼ | 
| `tnm` | = grad_normï¼Œ æ‰€æœ‰æ¢¯åº¦çš„L2èŒƒå¼ | 
| `tnm` | = grad_normï¼Œ æ‰€æœ‰æ¢¯åº¦çš„L2èŒƒå¼ | 
| `tnm` | = grad_normï¼Œ æ‰€æœ‰æ¢¯åº¦çš„L2èŒƒå¼ | 
| `tnm` | = grad_normï¼Œ æ‰€æœ‰æ¢¯åº¦çš„L2èŒƒå¼ | 
| `tnm` | = grad_normï¼Œ æ‰€æœ‰æ¢¯åº¦çš„L2èŒƒå¼ | 
| `tnm` | = grad_normï¼Œ æ‰€æœ‰æ¢¯åº¦çš„L2èŒƒå¼ | 
| `tnm` | = grad_normï¼Œ æ‰€æœ‰æ¢¯åº¦çš„L2èŒƒå¼ | 
## low_proj_for_sos
![](20250823214045.png)
## TextAttentivePool
![](20250823214131.png)


# diffusion
## betas = gd.get_named_beta_schedule(noise_schedule, diffusion_steps)
![](20250803151505.png)
![](20250803152247.png)
## def space_timesteps(num_timesteps, section_counts): 
![](20250803152117.png)
## def create_diffusion
timestep_respacing : section_counts
## timestep_map : LEARNED_RANGE
![](20250803153142.png)
## use_timesteps vs timestep_map
![](20250803162844.png)
## new_betas
new_betas[1 - alpha_cumprod / last_alpha]
## model_mean_type
EPSILON	æ¨¡å‹é¢„æµ‹çš„æ˜¯æ·»åŠ çš„å™ªå£° ğœ–
START_X	æ¨¡å‹ç›´æ¥é¢„æµ‹åŸå§‹å›¾åƒ  $ x_{0} $â€‹
## betas
shape(1000, )
type: ndarray
## posterior_variance
posterior_log_variance_clipped
posterior_mean_coef1
posterior_mean_coef2
![](20250803165440.png)
## q_mean_variance
![](20250803180811.png)
## _extract_into_tensor(...)
![](20250803180842.png)
## q_sample
sample from q(x_t | x_0).
return x_t
## signal
:param model: the model, which takes a signal and a batch of timesteps as input.
è¿™é‡Œçš„ signal æ˜¯æŒ‡ï¼šå½“å‰çš„æ‰©æ•£çŠ¶æ€å¼ é‡x_tï¼Œä¹Ÿå°±æ˜¯æ¨¡å‹åœ¨æŸä¸ªæ—¶é—´æ­¥ t ä¸Šæ¥æ”¶åˆ°çš„å›¾åƒæˆ–ç‰¹å¾è¾“å…¥ã€‚
## p_mean_variance(...)
![](20250804110349.png)
![](20250804110400.png)
xt->x0->q_posterior_mean_variance.mean
if learned_var: xt->var
else q_posterior_mean_variance.var
## _predict_xstart_from_eps,_predict_eps_from_xstart
![](20250804112507.png)
![](20250804112520.png)
## condition_mean
![](20250804113024.png)
## condition_score
![](20250804122052.png)
![](20250804122103.png)
xt->eps->x0->q_posterior_mean_variance.mean
## ddim_sample and ddim_reverse_sample
| `ddim_sample` | ç”Ÿæˆå›¾åƒ | æ­£å‘æ¨ç†ï¼ˆx\_T â†’ x\_0ï¼‰ | ä»éšæœºå™ªå£°é€æ­¥å»å™ªï¼Œç”Ÿæˆå›¾åƒ |
| --- |  --- |  --- |  --- |

| `ddim_reverse_sample` | ç¼–ç å›¾åƒ | åå‘æ¨ç†ï¼ˆx\_0 â†’ x\_Tï¼‰ | ä»åŸå§‹å›¾åƒåˆæˆå™ªå£°è½¨è¿¹ï¼Œç”¨äºè®­ç»ƒã€é‡å»ºæˆ–åå‘è°ƒæ§ |
| --- |  --- |  --- |  --- |
## DDIM
https://zhuanlan.zhihu.com/p/614147698

# tensorboard
## events.out.tfevents.{æ—¶é—´æˆ³}.{ä¸»æœºå}.{è¿›ç¨‹ID}{filename_suffix}
![](20250817194053.png)
## tensorboard --logdir .
æˆ–è€…local_output/__b4ep50adamlr0.0003wd0.005
## ps aux | grep tensorboard
## pkill -f tensorboard
## pkill -f tensorboard_data_server
## x = np.random.random(1000)
ç”Ÿæˆä¸€ä¸ª é•¿åº¦ä¸º 1000 çš„æ•°ç»„ï¼Œå…ƒç´ æ˜¯æœä» [0,1) åŒºé—´å‡åŒ€åˆ†å¸ƒ

# distracted

Bç«™è§†é¢‘ï¼Œåƒé¥­ï¼ŒèŠå¤©ï¼Œæƒ³æ‰“å¼€æ¸¸æˆç»ƒæª/è®¾ç½®å¿«æ·é”®,çœ‹qq


# çœ‹ä¸æ‡‚
## scale_schedule
![](20250729111602.png)
## progressive training
in var-origin
![](20250729111703.png)
## use_flex_attn

## attn_bias_or_two_vector

# SRVAR
## SRVAR::forward
inp_B3HW_low : [B, 3, H, W]
low_f : [B, 3, h, w] -> [B, C, h1, w1] using vartokenizer maybe
low_f : [B, h1*w1, C]

if(ref) low_f = [B, 2*h1*w1, C]

lowlen, lowC = 2*h1*w1, C
lens.shape = [B] 
max_seqlen_k = max lens
cu_seqlens_k = cumsum((0, lens))
kv_compact = [B, 2*h1*w1, C] = low_f
kv_compact = [B*2*h1*21, C]
kv_compact = [someplace(in lowlen unit) replaced by cfg_uncond] in dimension 0
cond_BD = sos = low_proj_for_sos(kv_compact) [B, C2] in this case C2 = 1024
cond_BD_or_gss = shared_ada_lin(cond_BD) # gss: gamma, scale, shift;torch.Size([4, 1024])

this thing later translate to [B, 6*C] through self.ada_lin in basic.py in line 517

sos : [B, C2]->[B, 1, C2]
x_BLC = (sos, x_BLC_wo_prefix) : [B, 680, C2]
l_end = 680
attn_bias_for_masking : [1, 1, l_end, l_end] this is masking

x_BLC->transformer->x_BLC
x_BLC : [B, 680, C2] -> [B, 680, C3] in this case C3 = 4096
return x_BLC

## SRtrainer::train_step

input : inp_B3HW_super : [B, 3, H, W]
gt_idx_Bl_super : img_to_idxBl(inp_B3HW_super) : ([B, 1], [B, 4], ... , [B, 256])
gt_BL_super = cat(gt_idx_Bl_super) : [B, 680]
x_BLCv_wo_first_l_super : idxBl_to_var_input(gt_idx_Bl_super) # torch.Size([4, 679, 32])


logits_BLV, diff_loss = SRVAR::forward(inp_B3HW_low, x_BLCv_wo_first_l_super)

loss = train_loss(logits_BLV.view(B * 680, C3), gt_BL_super.view(-1))

so this most important point is the two function:
1. img_to_idxBl
2. idxBl_to_var_input

## img_to_idxBl
## idxBl_to_var_input

## SRVAR::autoregressive_infer_cfg
low_f = encode(inp_B3HW_low) [1, 32, 16, 16] 
low_f : [1, 32, 16, 16] -> [1, 256, 32]

in the following context, B = 1
lowlen, lowC = 2*h1*w1, C
lens.shape = [B] 
max_seqlen_k = max lens
cu_seqlens_k = cumsum((0, lens))
kv_compact = [B, 2*h1*w1, C] = low_f
kv_compact = [B*2*h1*21, C]
kv_compact = [someplace(in lowlen unit) replaced by cfg_uncond] in dimension 0
cond_BD = sos = low_proj_for_sos(kv_compact) [B, C2] in this case C2 = 1024 

cond_BD_or_gss = shared_ada_lin(cond_BD) # gss: gamma, scale, shift;torch.Size([B, 1024]) è¿™é‡Œçš„Bä¹Ÿæ˜¯1
accu_BChw, cur_L, ret = None, 0, []  
idx_Bl_list = []

accu_BChw : [1, 32, 16, 16] all zero





## eval.ipynb

gt_idx_Bl_super : img_to_idxBl(inp_B3HW_super) : ([B, 1], [B, 4], ... , [B, 256])
gt_BL_super = cat(gt_idx_Bl_super) : [B, 680]
x_BLCv_wo_first_l_super : idxBl_to_var_input(gt_idx_Bl_super) # torch.Size([4, 679, 32])

ret, idx_Bl_list, img = srvar.autoregressive_infer_cfg(...)



# MAR

## forward_mae_encoder
input x : [B, L, C], mask : [B, L], class_embedding : [B, C]
x, mask : [b, L, c] -> [b, L + buffer_size, C]
x[:, :self.buffer_size] = class_embedding
x = x + pos_embed
x : [B, L, c] -> [B, L2, C] (mask, 0 æ˜¯æœ‰æ•ˆçš„ä¹Ÿå°±æ˜¯æ²¡æœ‰è¢«é®ä½çš„)
x -> transformer -> x
return x

## forward_mar_decoder
x : [B, L2, C], mask : [B, L]
mask : [B, L] -> [B, L + buffer_size]
mask_tokens : [1, 1, C] -> [B, L + buffer_size, C]
x_after_pad : [B, L + buffer_size, C] -> [B, L + buffer_size, C] (å°† x çš„å€¼ä¼ é€’ç»™ x_after_padä¸­ä¸º0 çš„éƒ¨åˆ†ï¼Œ é•¿åº¦åº”è¯¥åˆšåˆšå¥½)
x = x_after_pad + self.decoder_pos_embed_learned
x -> transformer -> x
x = x[:, self.buffer_size:]
x = x + self.diffusion_pos_embed_learned
return x

## forward_loss
input : z, mask, target : [B, L, C]
diffusion_batch_mul seems like 4?
diffusion_batch_mul = dbm
target : [B * L, C] -> [dbm * B * L, C]
z : [B * L, C] -> [dbm * B * L, C]
mask : [B * L, C] -> [dbm * B * L, C]
loss = diffloss(z, target, mask)
return loss

## DiffLoss::forward
input : target, z, mask : [B, L, C]
t : [B]
loss_dict = training_losses(self.net, target, t, model_kwargs)
loss : [B, L]
loss = (loss * mask) (ç›¸å½“äºmask ä¸º 1æ‰æ˜¯éœ€è¦é¢„æµ‹ï¼Œè®¡ç®—lossçš„)
loss = loss.sum() / mask.sum()
return loss.mean()

## sample_tokens
input : bsz = len(labels), num_iter, cfg_scale, cfg_schedule, labels : tupleï¼Œå…¶ä¸­æ¯ä¸€ä¸ªå…ƒç´ ä»£è¡¨æƒ³ç”Ÿæˆçš„ç±»å‹, temperature, progress : True(æ˜¯å¦è¿›åº¦æ¡)

mask : [b, L] ones
tokens : [b, L, C] zeros
orders : [b, C]
indices : [0, 1, 2, ... , num_iter - 1]
for step in indices:
    cur_tokens = tokens
    class_embedding = [bsz, C]
    tokens = tokens, tokens [2 * B, L]
    class_embedding = class_embedding, fake_latent [2 * B, C]
    mask = mask, mask [2 * B, L]

    x = forward_mae_encoder(tokens, mask, class_embedding) [2 * B, L1, C]
    z = forward_mae_decoder(x, mask) [2 * B, L, C]

    mask_ratio : smaller with step increase
    mask_len : mask_ratio * L
    // torch.sum(mask, dim=-1, keepdims=True)æ˜¯æœ€åä¸€ç»´å˜1çš„æ„æ€
    mask_len = max(1, min(len - 1, mask_len)) å…¶ä¸­lenä¸º mask ä¸­ 1 çš„ä¸ªæ•°ï¼Œä¹Ÿå°±æ˜¯è¢«é®æ© [B]
    
    def mask_by_order:
        masking : [B, L] zeros
        // torch.scatter(masking, dim=0, index=index, src=src), dim=0 çš„æ„æ€å°±æ˜¯indexå¡«å……çš„æ˜¯dim=0çš„æ•°æ®ï¼Œä¹Ÿå°±æ˜¯è¯´indexåˆ—çš„æ•°é‡ä¸€å®šè¦å’Œmaskingæ˜¯ä¸€æ ·çš„      
        masking : [B, mask]å¯¹åº”åœ°æ–¹å˜1ï¼Œæ¯ä¸ªbatchæœ‰ mask_lenè¿™ä¹ˆå¤šä¸ª1ï¼Œè¡¨ç¤ºè¢«é®æ©

    mask_next = mask_by_order(mask_len[0], orders, bsz, L)ï¼Œè¿™é‡Œæ³¨æ„ordersæ˜¯å¾ªç¯å¤–å®šä¹‰çš„ï¼Œæ‰€ä»¥ä¸ä¼šå‡ºç°ä¹‹å‰æœªè¢«maskçš„ç°åœ¨maskäº†ï¼Œä¸€å®šæ˜¯æŒ‰ç…§é¡ºåºçš„

